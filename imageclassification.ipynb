{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Explorer003/Data-Science-Projects/blob/main/imageclassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVEoMra54RYz"
      },
      "source": [
        "# **✨Image Detection Using Python**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liFmSezbFA4J"
      },
      "source": [
        "🥰Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N3XizNep6OVl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvcRtr7MFYuf"
      },
      "source": [
        "😺Importing the Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpeWGfLJ5zpb",
        "outputId": "cb46b4e7-cb25-4489-ae44-3cae4e486df7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "zip_path = '/content/drive/MyDrive/dataset.zip'\n",
        "import zipfile\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6y4gVOCFtlX"
      },
      "source": [
        "# 😰Part:1 Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_OQp_nyGNS_"
      },
      "source": [
        "Preprocessing the Training Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ2QD8uyGTCp",
        "outputId": "5069989a-1cbd-4d5d-efe6-6a6305fd6964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
        "                                                 target_size = (64,64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dXHbCVhR38t"
      },
      "source": [
        "Preprocessing the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH4WzfOhpKc3",
        "outputId": "16e65734-6fd1-4737-af1f-1d0925328600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3-SDF3iS82u"
      },
      "source": [
        "# **😉Part 2 : Building the CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSidMa5MTJQm"
      },
      "source": [
        "# ✌Initialising the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4eexRiWpT-0t"
      },
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neBZRQcsTR20"
      },
      "source": [
        "Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EPuWaj0nToZk"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6s2M9pETowM"
      },
      "source": [
        "Pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wRsASuXTTpvk"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYdtMkbXTp5j"
      },
      "source": [
        "Add a second convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VBBtmWmATugs"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BS0xjEfTuzx"
      },
      "source": [
        "Flattening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HrqKbhHmTxos"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYAojMAzTxyi"
      },
      "source": [
        "Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xYn8SW8nTzh8"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ysWTl2AT07E"
      },
      "source": [
        "Output layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kknCox4GTznV"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIZGdqxYUnws"
      },
      "source": [
        "# 😃Training the ***CNN***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvANBhRvUuHE"
      },
      "source": [
        "Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tvD3TqPfUzBs"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x8PJ0PJVSbB"
      },
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seiUi1V1VNZc",
        "outputId": "20accc0f-5ff7-4cde-d150-cf33e0a45d5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "250/250 [==============================] - 48s 148ms/step - loss: 0.6431 - accuracy: 0.6133 - val_loss: 0.6757 - val_accuracy: 0.6165\n",
            "Epoch 2/25\n",
            "250/250 [==============================] - 39s 156ms/step - loss: 0.5768 - accuracy: 0.6956 - val_loss: 0.5401 - val_accuracy: 0.7310\n",
            "Epoch 3/25\n",
            "250/250 [==============================] - 38s 153ms/step - loss: 0.5389 - accuracy: 0.7254 - val_loss: 0.5084 - val_accuracy: 0.7585\n",
            "Epoch 4/25\n",
            "250/250 [==============================] - 42s 168ms/step - loss: 0.5113 - accuracy: 0.7462 - val_loss: 0.4839 - val_accuracy: 0.7665\n",
            "Epoch 5/25\n",
            "250/250 [==============================] - 42s 168ms/step - loss: 0.4867 - accuracy: 0.7628 - val_loss: 0.4766 - val_accuracy: 0.7770\n",
            "Epoch 6/25\n",
            "250/250 [==============================] - 38s 153ms/step - loss: 0.4638 - accuracy: 0.7771 - val_loss: 0.4780 - val_accuracy: 0.7715\n",
            "Epoch 7/25\n",
            "250/250 [==============================] - 36s 146ms/step - loss: 0.4505 - accuracy: 0.7844 - val_loss: 0.5094 - val_accuracy: 0.7515\n",
            "Epoch 8/25\n",
            "250/250 [==============================] - 38s 153ms/step - loss: 0.4365 - accuracy: 0.7916 - val_loss: 0.4636 - val_accuracy: 0.7905\n",
            "Epoch 9/25\n",
            "250/250 [==============================] - 39s 155ms/step - loss: 0.4217 - accuracy: 0.8029 - val_loss: 0.4721 - val_accuracy: 0.7875\n",
            "Epoch 10/25\n",
            "250/250 [==============================] - 43s 172ms/step - loss: 0.4071 - accuracy: 0.8119 - val_loss: 0.4767 - val_accuracy: 0.7690\n",
            "Epoch 11/25\n",
            "250/250 [==============================] - 38s 153ms/step - loss: 0.3973 - accuracy: 0.8185 - val_loss: 0.4484 - val_accuracy: 0.7945\n",
            "Epoch 12/25\n",
            "250/250 [==============================] - 37s 146ms/step - loss: 0.3852 - accuracy: 0.8192 - val_loss: 0.4908 - val_accuracy: 0.7715\n",
            "Epoch 13/25\n",
            "250/250 [==============================] - 38s 151ms/step - loss: 0.3649 - accuracy: 0.8350 - val_loss: 0.4442 - val_accuracy: 0.8110\n",
            "Epoch 14/25\n",
            "250/250 [==============================] - 38s 152ms/step - loss: 0.3532 - accuracy: 0.8441 - val_loss: 0.4377 - val_accuracy: 0.8105\n",
            "Epoch 15/25\n",
            "250/250 [==============================] - 37s 149ms/step - loss: 0.3430 - accuracy: 0.8470 - val_loss: 0.4148 - val_accuracy: 0.8190\n",
            "Epoch 16/25\n",
            "250/250 [==============================] - 42s 170ms/step - loss: 0.3297 - accuracy: 0.8561 - val_loss: 0.4324 - val_accuracy: 0.8130\n",
            "Epoch 17/25\n",
            "250/250 [==============================] - 42s 169ms/step - loss: 0.3071 - accuracy: 0.8659 - val_loss: 0.4491 - val_accuracy: 0.8125\n",
            "Epoch 18/25\n",
            "250/250 [==============================] - 39s 154ms/step - loss: 0.2958 - accuracy: 0.8737 - val_loss: 0.4631 - val_accuracy: 0.8015\n",
            "Epoch 19/25\n",
            "250/250 [==============================] - 37s 149ms/step - loss: 0.2827 - accuracy: 0.8835 - val_loss: 0.4771 - val_accuracy: 0.8055\n",
            "Epoch 20/25\n",
            "250/250 [==============================] - 39s 154ms/step - loss: 0.2746 - accuracy: 0.8817 - val_loss: 0.4762 - val_accuracy: 0.8035\n",
            "Epoch 21/25\n",
            "250/250 [==============================] - 39s 156ms/step - loss: 0.2594 - accuracy: 0.8888 - val_loss: 0.5228 - val_accuracy: 0.7940\n",
            "Epoch 22/25\n",
            "250/250 [==============================] - 39s 158ms/step - loss: 0.2441 - accuracy: 0.9000 - val_loss: 0.5075 - val_accuracy: 0.7950\n",
            "Epoch 23/25\n",
            "250/250 [==============================] - 46s 184ms/step - loss: 0.2384 - accuracy: 0.8980 - val_loss: 0.4991 - val_accuracy: 0.8160\n",
            "Epoch 24/25\n",
            "250/250 [==============================] - 39s 158ms/step - loss: 0.2213 - accuracy: 0.9074 - val_loss: 0.5158 - val_accuracy: 0.8025\n",
            "Epoch 25/25\n",
            "250/250 [==============================] - 39s 157ms/step - loss: 0.2127 - accuracy: 0.9137 - val_loss: 0.5036 - val_accuracy: 0.7980\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f48201ae7a0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***🐹Making a single prediction***"
      ],
      "metadata": {
        "id": "FyUH3-Z0aiFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras.utils as image\n",
        "test_image = image.load_img('/content/dataset/test_set/dogs/dog.4001.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "462QBEFBark0",
        "outputId": "074c2b69-ced4-4b0c-8554-d4833a333cd3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAKMAfvhav8D",
        "outputId": "97c0ccc7-6752-4f57-a7cf-7072acb00cfe"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlSCVe3WdedWd9HFvSezDj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}